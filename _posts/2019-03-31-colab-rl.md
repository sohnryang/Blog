---
title: Reinforcement Learning in Google Colab
layout: post
tags: [python, google-colab, ml, rl]
---

딥러닝을 하려면 CUDA GPU는 거의 필수다. CPU로 학습시킬 수도 있긴 하지만 그리 권하고 싶지 않다. <strike>컴퓨터를 태워먹고 싶다면야</strike>

가장 큰 이유는 속도의 차이이다. 내가 직접 만든 [MNIST 손글씨 데이터셋을 분류하는 CNN](https://github.com/sohnryang/tensorflow-study/blob/master/jupyter-notebooks/MNIST%20classifying.ipynb)이 있는데, 이걸 당시 내 컴퓨터에서 돌렸을 때 20~30분 정도 걸린 것으로 기억한다.

GPU에서 돌리면? 겨우 1분 40초 걸린다. 18배씩이나 차이 난다. <strike>바보야 문제는 돈이야</strike>

차라리 학습 시간만 차이 난다면 문제없을 텐데, 학습시키던 당시 10변에 한번꼴로 내 컴퓨터는 과열되서 생사를 넘나들었고, 결국 AI 배우는 것은 접었다. [이 repo](https://github.com/sohnryang/tensorflow-study)의 마지막 commit 날짜만 봐도 알 수 있다.

그렇게 2018년에 [이 학교](https://ksa.hs.kr/) [저 학교](http://www.hansung-sh.hs.kr) 떨어지고 빡쳐서 [이런 거](https://github.com/minecraft-codingmath/pycraft-snu)나 [저런 거](https://github.com/sohnryang/boj-tool) 만들면서 방황하다가 다시 딥러닝을 배우기 시작했다.

다행히도 1년정도 지나니까 상황이 꽤 괜찮아진것 같다.

## Google Colab
공짜 GPU가 있다고 하면 아마 이런 일이 일어날 것이다.

![crypto-mining](https://i.imgur.com/piaAAhL.gif)

어쩌면 이것이 공짜 GPU를 잘 주지 않는 이유일지도 모른다. 다행히 돈많은 구글 신은 우리에게 공짜 GPU를 주셨다. 단, 무한정 켜둘 수는 없다지만, 그래도 공짜는 공짜이다. 심지어 TPU도 준다고 하는데, 굳이 그정도까지는 필요 없을것 같기도 하고, 내 benchmark에서는 오히려 GPU보다 못한 성능을 보이기도 했다.

Google Colab에서는 Jupyter Notebook을 편집하고, GPU나 TPU가 제공되는 환경에서 직접 실행할 수 있다. 몇가지 단축키가 빠져 있지만, 그래도 쓸만한 물건이다.

## OpenAI Gym
내가 Google Colab을 쓰는 이유는 강화 학습을 하기 위해서인데, 주로 OpenAI Gym을 이용할 예정이다. 원래 X윈도에서 화면이 돌아가야 사용 가능하지만, 몇가지 패키지를 설치하고, 설정을 해주면 CartPole과 같은 것이 돌아가는 것을 볼 수 있다.

우선 다음과 같이 패키지를 설치해주자.

```
!apt-get install -y python-numpy python-dev cmake zlib1g-dev libjpeg-dev xvfb \
    xorg-dev python-opengl libboost-all-dev libsdl2-dev swig
!pip install pyvirtualdisplay
!pip install piglet
```

그 다음 headless display <strike>모가지 날아간 display</strike>를 만들어준다.

```python
from pyvirtualdisplay import Display
display = Display(visible=0, size=(1400, 900))
display.start()
```

마지막으로 gameplay를 직접 보여주는 함수 몇가지를 만든다.

```python
def show_video():
    mp4_list = glob('video/*.mp4')
    if mp4_list:
        mp4 = mp4_list[0]
        video = open(mp4, 'r+b').read()
        encoded = b64encode(video)
        ipy_display.display(HTML(data='''
            <video alt="gameplay" autoplay controls style="height: 400px;">
                <source src="data:video/mp4;base64,%s" type="video/mp4" />
            </video>
        ''' % (encoded.decode('ascii'))))
    else:
        print('No video found')

def wrap_env(env):
    env = Monitor(env, './video', force=True)
    return env
```

[완성된 notebook](https://github.com/sohnryang/keras-reinforcement-learning/blob/master/templates/colab-template.ipynb)과 [cartpole을 랜덤하게 플레이하는 AI](https://github.com/sohnryang/keras-reinforcement-learning/blob/master/tutorial/cartpole.ipynb)는 내 깃허브에서 볼 수 있다.

이제 공부나 해야겠다.
